{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing similarity between individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(effects, effect_structure):\n",
    "    n_effects_chosen = random.randint(1, len(effects) - 2)\n",
    "    selected_effects = random.sample(effects, n_effects_chosen)\n",
    "    \n",
    "    individ = {}\n",
    "    for effect in selected_effects:\n",
    "        if effect in effect_structure:\n",
    "            structure = effect_structure[effect]\n",
    "            individ[effect] = {\n",
    "                param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "                for param, (_, range_) in structure.items()\n",
    "            }\n",
    "    return individ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_effects = 6\n",
    "effects = [i for i in range(n_effects)]\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (1.0, 20.0)), },# Chorus\n",
    "    1: { \"delay_seconds\": ('float', (1.0, 5.0)), },# Delay\n",
    "    2: { \"drive_db\": ('float', (1.0, 20.0)), },# Distortion\n",
    "    3: { \"gain_db\": ('float', (-10.0, 10.0)) },# Gain\n",
    "    4: { \"depth\": ('float', (0.2, 0.6)), },# Phaser\n",
    "    5: { \"wet_level\": ('float', (0.2, 0.6)), },# Reverb\n",
    "}\n",
    "effects_map = {\n",
    "    0: 'Chorus',\n",
    "    1: 'Delay',\n",
    "    2: 'Distortion',\n",
    "    3: 'Gain',\n",
    "    4: 'Phaser',\n",
    "    5: 'Reverb',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'rate_hz': 75.78}}\n",
      "{5: {'wet_level': 0.32}, 0: {'rate_hz': 43.73}, 2: {'drive_db': 7.99}}\n",
      "0.19235506290138119\n"
     ]
    }
   ],
   "source": [
    "individ1 = create_individual(effects, effect_structure)\n",
    "individ2 = create_individual(effects, effect_structure)\n",
    "\n",
    "print(individ1)\n",
    "print(individ2)\n",
    "\n",
    "# Extract common keys\n",
    "common_keys = individ1.keys() & individ2.keys()\n",
    "\n",
    "similarity_value = 0.0\n",
    "for key in common_keys:\n",
    "    weight = min(1 / len(individ1), 1 / len(individ2))\n",
    "    #print(f'Key: {key}, weight: {weight}')\n",
    "    \n",
    "    inner_dict = effect_structure[key]\n",
    "    lower_v = None\n",
    "    max_v = None\n",
    "    for param, value in inner_dict.items():\n",
    "        lower_v = value[1][0]\n",
    "        max_v = value[1][1]\n",
    "                \n",
    "    param_name = list(effect_structure[key].keys())[0]\n",
    "    r = individ1[key][param_name]\n",
    "    x = individ2[key][param_name]\n",
    "    \n",
    "    #print(\"r = \", r)\n",
    "    #print(\"x = \", x)\n",
    "    #print(\"low limit = \", lower_v)\n",
    "    #print(\"max limit = \", max_v)\n",
    "    \n",
    "    distance_to_lower_v = abs(r - lower_v)\n",
    "    distance_to_max_v = abs(r - max_v)\n",
    "    \n",
    "    limit_chosen = None\n",
    "    if distance_to_lower_v < distance_to_max_v:\n",
    "        limit_chosen = max_v\n",
    "    else:\n",
    "        limit_chosen = lower_v\n",
    "    \n",
    "    #print(\"abs(x - r) = \", abs(x - r))\n",
    "    #print(\"abs(r - limit_chosen) = \", abs(r - limit_chosen))\n",
    "    \n",
    "    obtained_value_normalized = 1 - abs(x - r)/abs(r - limit_chosen)\n",
    "    similarity_value += weight * obtained_value_normalized\n",
    "    \n",
    "print(similarity_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_individuals(individ1, individ2):\n",
    "    common_keys = individ1.keys() & individ2.keys()\n",
    "    similarity = 0.0\n",
    "    for key in common_keys:\n",
    "        weight = min(1 / len(individ1), 1 / len(individ2))        \n",
    "        inner_dict = effect_structure[key]\n",
    "        param_name, (range_name, (lower_v, max_v)) = next(iter(inner_dict.items()))\n",
    "         \n",
    "        param_name = list(effect_structure[key].keys())[0]\n",
    "        r = individ1[key][param_name]\n",
    "        x = individ2[key][param_name]\n",
    "        \n",
    "        limit_chosen = max_v if abs(r - lower_v) < abs(r - max_v) else lower_v\n",
    "        \n",
    "        obtained_value_normalized = 1 - abs(x - r)/abs(r - limit_chosen)\n",
    "        similarity += weight * obtained_value_normalized\n",
    "        \n",
    "    return similarity\n",
    "\n",
    "def similarity_individuals_effect_only(individ1, individ2):\n",
    "    common_keys = individ1.keys() & individ2.keys()\n",
    "    similarity = 0.0\n",
    "    for _ in common_keys:\n",
    "        weight = min(1 / len(individ1), 1 / len(individ2)) \n",
    "        similarity += weight\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'gain_db': -1.5}, 1: {'delay_seconds': 1.62}}\n",
      "{1: {'delay_seconds': 1.62}}\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "individ1 = {3: {'gain_db': -1.5}, 1: {'delay_seconds': 1.62}}\n",
    "individ2 = {1: {'delay_seconds': 1.62}}\n",
    "similarity = similarity_individuals(individ1, individ2)\n",
    "\n",
    "print(individ1)\n",
    "print(individ2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8472474768348054\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "a = np.array([1, 1, 1, 1, 1, 1])\n",
    "b = np.array([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "s_max = np.sqrt(np.sum(np.square(a - b))) #similaritÃ  euclidea\n",
    "\n",
    "a = np.array([0.5, 0, 0, 0, 0, 0])\n",
    "b = np.array([0.2, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "s = np.sqrt(np.sum(np.square(a - b)))\n",
    "\n",
    "\n",
    "print((s_max - s)/ s_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized array A: [0.20210526 0.         0.00631579 0.         0.7        0.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = {0: {'rate_hz': 4.84}, 2: {'drive_db': 1.12}, 4: {'depth': 0.48}, 5: {'wet_level': 0.2  }}\n",
    "\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (1.0, 20.0)) },  # Chorus\n",
    "    1: { \"delay_seconds\": ('float', (1.0, 5.0)) },  # Delay\n",
    "    2: { \"drive_db\": ('float', (1.0, 20.0)) },  # Distortion\n",
    "    3: { \"gain_db\": ('float', (-10.0, 10.0)) },  # Gain\n",
    "    4: { \"depth\": ('float', (0.2, 0.6)) },  # Phaser\n",
    "    5: { \"wet_level\": ('float', (0.2, 0.6)) },  # Reverb\n",
    "}\n",
    "\n",
    "# Function to normalize a value within a given range\n",
    "def normalize(value, min_val, max_val):\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "# Initialize an array with zeros for all effects\n",
    "B = np.zeros(n_effects)\n",
    "\n",
    "# Iterate over each effect in 'a'\n",
    "for effect_id, params in a.items():\n",
    "    for param_name, param_value in params.items():\n",
    "        _, (min_val, max_val) = effect_structure[effect_id][param_name]\n",
    "        # Normalize the parameter value\n",
    "        normalized_value = normalize(param_value, min_val, max_val)\n",
    "        # Assign the normalized value to the corresponding position in B\n",
    "        B[effect_id] = normalized_value\n",
    "\n",
    "# Convert B to a numpy array A\n",
    "A = np.array(B)\n",
    "\n",
    "print(\"Normalized array A:\", A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(value, min_val, max_val):\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "def similarity_array(individ, effect_structure, n_effects):\n",
    "    sim_array = np.zeros(n_effects)\n",
    "\n",
    "    for effect_id, params in individ.items():\n",
    "        for param_name, param_value in params.items():\n",
    "            \n",
    "            if effect_id == 3 and param_name == 'gain_db':\n",
    "                param_value += 10  # Apply the translation\n",
    "                \n",
    "            _, (min_val, max_val) = effect_structure[effect_id][param_name]\n",
    "            # Normalize the parameter value\n",
    "            normalized_value = normalize(param_value, min_val, max_val)\n",
    "            # Assign the normalized value to the corresponding position in B\n",
    "            sim_array[effect_id] = normalized_value\n",
    "\n",
    "    # Convert B to a numpy array A\n",
    "    return np.array(sim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20210526 0.         0.00631579 0.         0.7        0.        ]\n"
     ]
    }
   ],
   "source": [
    "a = {0: {'rate_hz': 4.84}, 2: {'drive_db': 1.12}, 4: {'depth': 0.48}, 5: {'wet_level': 0.2  }}\n",
    "\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (1.0, 20.0)) },  # Chorus\n",
    "    1: { \"delay_seconds\": ('float', (1.0, 5.0)) },  # Delay\n",
    "    2: { \"drive_db\": ('float', (1.0, 20.0)) },  # Distortion\n",
    "    3: { \"gain_db\": ('float', (-10.0, 10.0)) },  # Gain\n",
    "    4: { \"depth\": ('float', (0.2, 0.6)) },  # Phaser\n",
    "    5: { \"wet_level\": ('float', (0.2, 0.6)) },  # Reverb\n",
    "}\n",
    "\n",
    "\n",
    "print(similarity_array(a, effect_structure, len(effect_structure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_calculation(sim_array1, sim_array2, sim_max):\n",
    "    sim = np.sqrt(np.sum(np.square(sim_array1 - sim_array2)))\n",
    "    return (sim_max - sim)/ sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.    0.    0.909 0.    0.   ]\n",
      "[0.  0.  0.  0.2 0.  0. ]\n",
      "0.710551962061121\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones(6)  \n",
    "zeros = np.zeros(6)\n",
    "\n",
    "sim_max = np.sqrt(np.sum(np.square(ones - zeros))) #similaritÃ  euclidea\n",
    "\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (0.0, 20.0)) },  # Chorus\n",
    "    1: { \"delay_seconds\": ('float', (0.0, 5.0)) },  # Delay\n",
    "    2: { \"drive_db\": ('float', (0.0, 20.0)) },  # Distortion\n",
    "    3: { \"gain_db\": ('float', (0, 20.0)) },  # Gain\n",
    "    4: { \"depth\": ('float', (0.0, 0.6)) },  # Phaser\n",
    "    5: { \"wet_level\": ('float', (0.0, 0.6)) },  # Reverb\n",
    "}\n",
    "\n",
    "'''\n",
    "    0: { \"rate_hz\": ('float', (1.0, 20.0)) },  # Chorus\n",
    "    1: { \"delay_seconds\": ('float', (1.0, 5.0)) },  # Delay\n",
    "    2: { \"drive_db\": ('float', (1.0, 20.0)) },  # Distortion\n",
    "    3: { \"gain_db\": ('float', (-10.0, 10.0)) },  # Gain\n",
    "    4: { \"depth\": ('float', (0.2, 0.6)) },  # Phaser\n",
    "    5: { \"wet_level\": ('float', (0.2, 0.6)) },  # Reverb\n",
    "'''\n",
    "\n",
    "individ1 = {3: {'gain_db': 8.18}}\n",
    "individ2 = {3: {'gain_db': -6}}\n",
    "\n",
    "sim_array1 = similarity_array(individ1, effect_structure, len(effect_structure))\n",
    "sim_array2 = similarity_array(individ2, effect_structure, len(effect_structure))\n",
    "print(sim_array1)\n",
    "print(sim_array2)\n",
    "\n",
    "print(similarity_calculation(sim_array1, sim_array2, sim_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing similarity on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search.csv')\n",
    "similarities = []\n",
    "for index, row in df.iterrows():\n",
    "    applied_effects = row['applied_effects']\n",
    "    ga_effects = row['GA_effects']\n",
    "\n",
    "    # Convert the string representations to dictionaries\n",
    "    if pd.notnull(applied_effects) and pd.notnull(ga_effects):\n",
    "        try:\n",
    "            applied_effects = ast.literal_eval(applied_effects)\n",
    "            ga_effects = ast.literal_eval(ga_effects)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error converting row {index}: {e}\")\n",
    "            similarities.append(None)\n",
    "            continue\n",
    "\n",
    "        # Perform the similarity calculation\n",
    "        similarities.append(similarity_individuals(applied_effects, ga_effects))\n",
    "    else:\n",
    "        # If either field is missing, append a None or other placeholder value\n",
    "        similarities.append(None)\n",
    "        \n",
    "# Add the 'similarity_indv' column to the DataFrame\n",
    "df['similarity_indv'] = pd.Series(similarities)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./results/dataset_audios_guitar_lowR_1effect.csv')\n",
    "\n",
    "df.insert(df.columns.get_loc('GA_effects_OR') + 1, 'random_effects', '')\n",
    "df.to_csv('./results/dataset_audios_guitar_lowR_1effect.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test individual similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/dataset_audios_guitar_low_ranges_w_clean.csv')\n",
    "similarities = []\n",
    "similarities_effects_only = []\n",
    "for index, row in df.iterrows():\n",
    "    applied_effects = row['applied_effects']\n",
    "    ga_effects = row['GA_effects']\n",
    "\n",
    "    # Convert the string representations to dictionaries\n",
    "    if pd.notnull(applied_effects) and pd.notnull(ga_effects):\n",
    "        try:\n",
    "            applied_effects = ast.literal_eval(applied_effects)\n",
    "            ga_effects = ast.literal_eval(ga_effects)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error converting row {index}: {e}\")\n",
    "            similarities.append(None)\n",
    "            continue\n",
    "\n",
    "        # Perform the similarity calculation\n",
    "        similarities.append(similarity_individuals(applied_effects, ga_effects))\n",
    "        similarities_effects_only.append(similarity_individuals_effect_only(applied_effects, ga_effects))\n",
    "    else:\n",
    "        # If either field is missing, append a None or other placeholder value\n",
    "        similarities.append(None)\n",
    "        similarities_effects_only.append(None)\n",
    "        \n",
    "# Add the 'similarity_indv' column to the DataFrame\n",
    "df['similarity_indv'] = pd.Series(similarities)\n",
    "df['similarity_indv_effects_only'] = pd.Series(similarities_effects_only)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv('./results/dataset_audios_guitar_low_ranges_w_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search.csv')\n",
    "df['GA_effects'] = pd.Series('')\n",
    "df['similarity_indv'] = pd.Series('')\n",
    "df.to_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing NEW similarity on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search_new_diss.csv')\n",
    "\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (0.0, 20.0)) },  # Chorus\n",
    "    1: { \"delay_seconds\": ('float', (0.0, 5.0)) },  # Delay\n",
    "    2: { \"drive_db\": ('float', (0.0, 20.0)) },  # Distortion\n",
    "    3: { \"gain_db\": ('float', (0, 20.0)) },  # Gain\n",
    "    4: { \"depth\": ('float', (0.0, 0.6)) },  # Phaser\n",
    "    5: { \"wet_level\": ('float', (0.0, 0.6)) },  # Reverb\n",
    "}\n",
    "\n",
    "ones = np.ones(6)  \n",
    "zeros = np.zeros(6)\n",
    "\n",
    "sim_max = np.sqrt(np.sum(np.square(ones - zeros))) #similaritÃ  euclidea\n",
    "\n",
    "similarities = []\n",
    "for index, row in df.iterrows():\n",
    "    applied_effects = row['applied_effects']\n",
    "    ga_effects = row['GA_effects']\n",
    "\n",
    "    # Convert the string representations to dictionaries\n",
    "    if pd.notnull(applied_effects) and pd.notnull(ga_effects):\n",
    "        try:\n",
    "            applied_effects = ast.literal_eval(applied_effects)\n",
    "            ga_effects = ast.literal_eval(ga_effects)\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Error converting row {index}: {e}\")\n",
    "            similarities.append(None)\n",
    "            continue\n",
    "        \n",
    "        sim_array1 = similarity_array(applied_effects, effect_structure, len(effect_structure))\n",
    "        sim_array2 = similarity_array(ga_effects, effect_structure, len(effect_structure))\n",
    "\n",
    "        similarities.append(similarity_calculation(sim_array1, sim_array2, sim_max))\n",
    "        \n",
    "# Add the 'similarity_indv' column to the DataFrame\n",
    "df['similarity_indv'] = pd.Series(similarities)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "df.to_csv('./results/dataset_audios_guitar_low_ranges_w_clean_random_search_new_diss.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA_testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
