{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio to MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.5.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pelli\\anaconda3\\envs\\tensorflow_v2\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n",
      "Fail to import BlobReader from libmilstoragepython. No module named 'coremltools.libmilstoragepython'\n",
      "Fail to import BlobWriter from libmilstoragepython. No module named 'coremltools.libmilstoragepython'\n",
      "WARNING:root:tflite-runtime is not installed. If you plan to use a TFLite Model, reinstall basic-pitch with `pip install 'basic-pitch tflite-runtime'` or `pip install 'basic-pitch[tf]'\n"
     ]
    }
   ],
   "source": [
    "from basic_pitch import ICASSP_2022_MODEL_PATH, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_midi(audio_path, midi_path):\n",
    "    _, midi_data, __ = inference.predict(\n",
    "        audio_path,    \n",
    "        model_or_model_path = ICASSP_2022_MODEL_PATH, \n",
    "        onset_threshold = 0.6, #note segmentation 1) how easily a note should be split into two. (split notes <- ..0.5.. -> merge notes)\n",
    "        frame_threshold = 0.6, #model confidence threshold 2) the model confidence required to create a note. (more notes <- ..0.3.. -> fewer notes)\n",
    "    )\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        instrument.program = 30 #distortion guitar program\n",
    "\n",
    "    midi_data.write(midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting MIDI for input_audio_to_midi/3.mp3...\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"input_audio_to_midi/3.mp3\"\n",
    "midi_path = \"output_audio_to_midi/3.mid\"\n",
    "\n",
    "mp3_to_midi(audio_path, midi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other method to create the midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference.predict_and_save(\n",
    "#    audio_path_list = [audio_path],\n",
    "#    output_directory = \"output_audio_to_midi\",\n",
    "#    save_midi = True,\n",
    "#    sonify_midi = False,\n",
    "#    save_model_outputs = False,\n",
    "#    save_notes = False,\n",
    "#    model_or_model_path = ICASSP_2022_MODEL_PATH,\n",
    "#    #midi_tempo = tempo, #BPM\n",
    "#    onset_threshold = 0.6, #note segmentation 1)\n",
    "#    frame_threshold = 0.6, #model confidence threshold 2)\n",
    "#    multiple_pitch_bends = True\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play back the midi file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinysoundfont\n",
    "import time\n",
    "\n",
    "synth = tinysoundfont.Synth()\n",
    "sfid = synth.sfload(\"FluidR3_GM.sf2\")\n",
    "\n",
    "seq = tinysoundfont.Sequencer(synth)\n",
    "seq.midi_load(\"output_audio_to_midi/scala_basic_pitch.mid\")\n",
    "\n",
    "# Larger buffer because latency is not important\n",
    "synth.start(buffer_size=4096)\n",
    "\n",
    "while not seq.is_empty():\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the .sfx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinysoundfont\n",
    "\n",
    "# Load the SoundFont\n",
    "synth = tinysoundfont.Synth()\n",
    "sfid = synth.sfload(\"FluidR3_GM.sf2\")\n",
    "\n",
    "# List all the presets in the SoundFont\n",
    "for bank in range(128):  # MIDI supports up to 128 banks\n",
    "    for preset in range(128):  # Each bank has up to 128 presets\n",
    "        preset_name = synth.sfpreset_name(sfid, bank, preset)\n",
    "        if preset_name:\n",
    "            print(f\"Bank {bank}, Preset {preset}: {preset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDI to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midi2audio import FluidSynth \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_mp3(midi_file, mp3_file, soundfont):\n",
    "    #convert MIDI to WAV using FluidSynth\n",
    "    fs = FluidSynth(soundfont)\n",
    "    wav_file = midi_file.replace('.midi', '.wav').replace('.mid', '.wav')\n",
    "    fs.midi_to_audio(midi_file, wav_file)\n",
    "\n",
    "    #convert WAV to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(wav_file)\n",
    "    sound.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "    print(f\"Conversion complete: {mp3_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: output_audio_to_midi/3_output.mp3\n"
     ]
    }
   ],
   "source": [
    "midi_file = \"output_audio_to_midi/3.mid\"\n",
    "mp3_file = \"output_audio_to_midi/3_output.mp3\"\n",
    "soundfont = 'FluidR3_GM.sf2'  # Path to your SoundFont file\n",
    "\n",
    "midi_to_mp3(midi_file, mp3_file, soundfont)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
