{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Coremltools is not installed. If you plan to use a CoreML Saved Model, reinstall basic-pitch with `pip install 'basic-pitch[coreml]'`\n",
      "WARNING:root:tflite-runtime is not installed. If you plan to use a TFLite Model, reinstall basic-pitch with `pip install 'basic-pitch tflite-runtime'` or `pip install 'basic-pitch[tf]'\n",
      "WARNING:root:onnxruntime is not installed. If you plan to use an ONNX Model, reinstall basic-pitch with `pip install 'basic-pitch[onnx]'`\n",
      "WARNING:tensorflow:From c:\\Users\\pelli\\anaconda3\\envs\\GA_testing_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pedalboard import Pedalboard, Reverb, Chorus, Distortion, Delay, Phaser, Compressor, Gain, Clipping\n",
    "from pedalboard.io import AudioFile\n",
    "from collections import defaultdict\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import maximum_filter\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from statistics import NormalDist\n",
    "from scipy.ndimage import label as label_features\n",
    "from scipy.ndimage import maximum_position as extract_region_maximums\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "from copy import deepcopy \n",
    "import pandas as pd\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH, inference\n",
    "from midi2audio import FluidSynth \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(effects, effect_structure):\n",
    "    n_effects_chosen = random.randint(1, len(effects) - 2)\n",
    "    selected_effects = random.sample(effects, n_effects_chosen)\n",
    "    \n",
    "    individ = {}\n",
    "    for effect in selected_effects:\n",
    "        if effect in effect_structure:\n",
    "            structure = effect_structure[effect]\n",
    "            individ[effect] = {\n",
    "                param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "                for param, (_, range_) in structure.items()\n",
    "            }\n",
    "    return individ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_effects = 6\n",
    "effects = [i for i in range(n_effects)]\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (0.0, 100.0)), },# Chorus\n",
    "    1: { \"delay_seconds\": ('float', (0.0, 10.0)), },# Delay\n",
    "    2: { \"drive_db\": ('float', (0.0, 50.0)), },# Distortion\n",
    "    3: { \"gain_db\": ('float', (-50.0, 50.0)) },# Gain\n",
    "    4: { \"depth\": ('float', (0.0, 1.0)), },# Phaser\n",
    "    5: { \"wet_level\": ('float', (0.0, 1.0)), },# Reverb\n",
    "}\n",
    "effects_map = {\n",
    "    0: 'Chorus',\n",
    "    1: 'Delay',\n",
    "    2: 'Distortion',\n",
    "    3: 'Gain',\n",
    "    4: 'Phaser',\n",
    "    5: 'Reverb',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'drive_db': 47.19}, 1: {'delay_seconds': 0.45}, 0: {'rate_hz': 79.44}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_individual(effects, effect_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio with effect creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effected_audio(board, file_path):\n",
    "    with AudioFile(file_path) as f:\n",
    "        output_file = file_path[:-4] + \"_output.mp3\"\n",
    "        with AudioFile(output_file, 'w', f.samplerate, f.num_channels) as o:\n",
    "            while f.tell() < f.frames:\n",
    "                chunk = f.read(f.samplerate)\n",
    "                effected = board(chunk, f.samplerate, reset=False)\n",
    "                o.write(effected)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constellation map builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_window_peaks_calculation(file_path, threshold): \n",
    "    #step 1: Set parameters\n",
    "    N_FFT = 2048  # FFT window size\n",
    "    N_O = N_FFT // 4\n",
    "\n",
    "    #step 2: Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    #step 3: Compute the spectrogram\n",
    "    D = librosa.stft(y, n_fft=N_FFT, hop_length=N_O)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    \n",
    "    #step 4: Define window lengths for peak detection  \n",
    "    d_t = 15\n",
    "    d_f = 15\n",
    "\n",
    "    #step 5: Select settings for peak detection\n",
    "    #using maximum filter to detect local maxima\n",
    "    local_max = maximum_filter(S_db, size=(d_t, d_f))\n",
    "\n",
    "    #step 6: Create an identification matrix\n",
    "    peaks = (S_db == local_max)  # Peaks are where the original value is equal to the local max\n",
    "\n",
    "    #step 6.5: Apply an amplitude threshold to filter out insignificant peaks\n",
    "    amplitude_threshold = threshold  # dB, adjust as needed\n",
    "    peaks &= (S_db > amplitude_threshold)\n",
    "\n",
    "    #step 7: Extract peaks (time, frequency, amplitude)\n",
    "    times = librosa.frames_to_time(np.arange(S_db.shape[1]), sr=sr, hop_length=N_O)\n",
    "    frequencies = librosa.fft_frequencies(sr=sr, n_fft=N_FFT)\n",
    "\n",
    "    peak_indices = np.where(peaks)\n",
    "    peak_times = times[peak_indices[1]]\n",
    "    peak_freqs = frequencies[peak_indices[0]]\n",
    "    peak_ampls = S_db[peak_indices]\n",
    "\n",
    "    #save the peaks to a file (optional)\n",
    "    peak_data = np.vstack((peak_times, peak_freqs, peak_ampls)).T\n",
    "    peak_data_filtered = np.array([[round(x, 1), round(y, 1)] for x, y, _ in peak_data])\n",
    "    \n",
    "    return peak_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_peaks_calculation(file_path, threshold):\n",
    "    y, _ = librosa.load(path=file_path, sr=None)\n",
    "\n",
    "    #do transformations\n",
    "    x = librosa.stft(y)\n",
    "    x = librosa.amplitude_to_db(abs(x))\n",
    "    \n",
    "    #remove zero values\n",
    "    flattened = np.matrix.flatten(x)\n",
    "    filtered = flattened[flattened > np.min(flattened)]\n",
    "\n",
    "    #create a normal distribution from frequency intensities\n",
    "    #then map a zscore onto each intensity value\n",
    "    ndist = NormalDist(np.mean(filtered), np.std(filtered))\n",
    "    zscore = np.vectorize(lambda x: ndist.zscore(x))\n",
    "    zscore_matrix = zscore(x)\n",
    "\n",
    "    #create label matrix from frequency intensities that are\n",
    "    #above threshold\n",
    "    mask_matrix = zscore_matrix > threshold\n",
    "    labelled_matrix, num_regions = label_features(mask_matrix)\n",
    "    label_indices = np.arange(num_regions) + 1\n",
    "\n",
    "    #for each isolated region in the mask, identify the maximum\n",
    "    #value, then extract it position\n",
    "    peak_positions = extract_region_maximums(zscore_matrix, labelled_matrix, label_indices)\n",
    "\n",
    "    #finally, create list of peaks (time, frequency, intensity)\n",
    "    peaks = [[x, y] for y, x in peak_positions]\n",
    "\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissimilarity calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Euclidean distance function\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "# Define Gaussian neighborhood function\n",
    "def neighborhood_function(i, j, n, m, A=2, sigma=5):\n",
    "    return A * np.exp(-((i + 1 - (n - 1) * (j - 1) / (m - 1))**2) / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_epsilon_to_zeros(D, epsilon):\n",
    "  D_copy = D.copy()  # Create a copy to avoid modifying the original array\n",
    "  D_copy[D_copy == 0.0] = epsilon\n",
    "  return D_copy\n",
    "\n",
    "# Initialize membership matrix U based on initial distances and neighborhood function\n",
    "def initialize_membership(X, Y, neighborhood_func, epsilon):\n",
    "    n, m = len(X), len(Y)\n",
    "    D = cdist(X, Y, metric='euclidean')\n",
    "    D = add_epsilon_to_zeros(D, epsilon)\n",
    "    U = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            U[i, j] = 1.0 / np.sum([(D[i, j] / (D[i, k])) ** 2 for k in range(m)])\n",
    "            #U[i, j] *= neighborhood_func(i, j, n, m)\n",
    "        #U[i, :] /= np.sum([U[i, k] * neighborhood_func(i, k, n, m) for k in range(m)])\n",
    "    return U\n",
    "  \n",
    "# Update membership matrix using FOCM\n",
    "def update_membership(U, D, gamma, n_clusters, neighborhood_func):\n",
    "    n, m = U.shape\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            denominator = np.sum([(D[i, j] / (D[i, k])) ** (2 / (gamma - 1)) for k in range(n_clusters)])\n",
    "            U[i, j] = 1.0 / denominator\n",
    "            #U[i, j] *= neighborhood_func(i, j, n, m) #da rivedere perchè togliere questo\n",
    "\n",
    "        #U[i, :] /= np.sum([U[i, k] * neighborhood_func(i, k, n, m) for k in range(m)])\n",
    "    return U\n",
    "  \n",
    "# Calculate new cluster centers\n",
    "def calculate_cluster_centers(U, X, gamma):\n",
    "  U_gamma = np.power(U.T, gamma)\n",
    "  return (U_gamma @ X) / np.sum(U_gamma, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FOCM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOCM algorithm\n",
    "def focm(X, Y, n_clusters, max_iter=50, epsilon=1e-4, gamma=5):\n",
    "    U = initialize_membership(X, Y, neighborhood_function, epsilon)\n",
    "    V = np.copy(Y)\n",
    "    prev_U = np.zeros_like(U)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # Calculate distances\n",
    "        D = cdist(X, V, metric='euclidean')\n",
    "        D = add_epsilon_to_zeros(D, epsilon)\n",
    "\n",
    "        # Update membership matrix\n",
    "        U = update_membership(U, D, gamma, n_clusters, neighborhood_function)\n",
    "        \n",
    "        # Calculate new cluster centers\n",
    "        V = calculate_cluster_centers(U, X, gamma)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(U - prev_U) < epsilon:\n",
    "            break\n",
    "        prev_U = np.copy(U)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Core function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity_focm(file_path, output_file_path, constellation_map_alg, threshold):\n",
    "    peaks_1 = constellation_map_alg(file_path, threshold)\n",
    "    peaks_2 = constellation_map_alg(output_file_path, threshold)\n",
    "    \n",
    "    print(f\"{file_path}, len peaks: {len(peaks_1)}\")\n",
    "    print(f\"{output_file_path}, len peaks: {len(peaks_2)}\")\n",
    "    \n",
    "    if len(peaks_1) > len(peaks_2):\n",
    "        n_clusters = len(peaks_2)\n",
    "        M_A = deepcopy(peaks_1)\n",
    "        M_B = deepcopy(peaks_2)\n",
    "    else:\n",
    "        n_clusters = len(peaks_1)\n",
    "        M_A = deepcopy(peaks_2)\n",
    "        M_B = deepcopy(peaks_1) \n",
    "    \n",
    "    n_clusters = len(M_B)\n",
    "    U = focm(M_A, M_B, n_clusters)\n",
    "    \n",
    "    total_distance = 0\n",
    "\n",
    "    for i in range(len(M_A)):\n",
    "        for j in range(len(M_B)):\n",
    "            total_distance += U[i, j] * euclidean_distance(M_A[i], M_B[j])\n",
    "\n",
    "    return total_distance / (len(M_A) * len(M_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(hashes):\n",
    "    database = defaultdict(list)\n",
    "    for hash_value, time_offset in hashes:\n",
    "        database[hash_value].append(time_offset)\n",
    "    return database\n",
    "\n",
    "def generate_hashes(constellation_map, fan_out=10):\n",
    "    hashes = []\n",
    "    for anchor in constellation_map:\n",
    "        for target in constellation_map:\n",
    "            if target[0] > anchor[0]:  #ensure target is after anchor in time\n",
    "                delta_t = target[0] - anchor[0]\n",
    "                freq1, freq2 = anchor[1], target[1]\n",
    "                hash_value = (freq1, freq2, delta_t)\n",
    "                hashes.append((hash_value, anchor[0]))  # (hash_value, time_offset)\n",
    "                \n",
    "                #limit the fan-out to a certain number of target points\n",
    "                if len(hashes) >= fan_out:\n",
    "                    break\n",
    "    return hashes\n",
    "\n",
    "def search_database(database, sample_hashes):\n",
    "    match_offsets = []\n",
    "    for hash_value, sample_offset in sample_hashes:\n",
    "        if hash_value in database:\n",
    "            for track_offset in database[hash_value]:\n",
    "                match_offsets.append((track_offset, sample_offset))\n",
    "                database[hash_value] = database[hash_value][1:]\n",
    "                break\n",
    "    return match_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Core Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity_lines_difference(m1, q1, m2, q2, intersection_too_far):\n",
    "    if m1 == m2 or intersection_too_far:\n",
    "        if q1 == q2:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return abs(q2 - q1) / math.sqrt(1 + m1**2) #distance of the 2 parallel lines\n",
    "    else: #lines intersect\n",
    "        if m1 * m2 == -1:\n",
    "            return 90.0\n",
    "        else:\n",
    "            tan_theta = abs((m1 - m2) / (1 + m1 * m2))\n",
    "            theta_radians = math.atan(tan_theta)\n",
    "            theta_degrees = math.degrees(theta_radians)\n",
    "            return theta_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_focm(individual, file_path, effected_file_path, constellation_map_alg, threshold):\n",
    "    board = Pedalboard([])\n",
    "    for effect_key, params in individual.items():\n",
    "        effect_class = globals()[effects_map[effect_key]]\n",
    "        board.append(effect_class(**params))\n",
    "        \n",
    "    output_file_path = create_effected_audio(board, file_path)\n",
    "    diss = dissimilarity_focm(effected_file_path, output_file_path, constellation_map_alg, threshold)\n",
    "    print(f\"Individ: {individual} : diss: {diss}\")\n",
    "    return diss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing (modify file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing fitness function\n",
    "individ = {5: {'wet_level': 0.8}}\n",
    "file_path = \"G4_guitar.mp3\"\n",
    "effected_file_path = \"G4_guitar_Reverb_high.mp3\"\n",
    "fitness_focm(individ, file_path, effected_file_path, max_window_peaks_calculation, -20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_func(x, a, b):\n",
    "    return a * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_lines_difference(individual, plain_audio_path, hash_table, m1, q1, original_or_times, constellation_map_alg, threshold, fan_out):\n",
    "    board = Pedalboard([])\n",
    "    for effect_key, params in individual.items():\n",
    "        effect_class = globals()[effects_map[effect_key]]\n",
    "        board.append(effect_class(**params))\n",
    "        \n",
    "    output_file_path = create_effected_audio(board, plain_audio_path)\n",
    "    \n",
    "    new_peaks = constellation_map_alg(output_file_path, threshold)\n",
    "    new_hashes = generate_hashes(new_peaks, fan_out)\n",
    "    copy_hash_table = deepcopy(hash_table)\n",
    "    time_pairs = search_database(copy_hash_table, new_hashes)\n",
    "    \n",
    "    #print(len(original_or_times))\n",
    "    #print(len(time_pairs))\n",
    "    if len(time_pairs) >= 2:\n",
    "        or_times, sample_times = zip(*time_pairs)\n",
    "        if (len(or_times) / len(original_or_times)) >= 0.1: #there is at least some confidence\n",
    "            #print(len(original_or_times) / len(or_times))\n",
    "            popt1, _ = curve_fit(linear_func, or_times, sample_times)\n",
    "            m2, q2 = popt1\n",
    "            \n",
    "            max_x = max(original_or_times)\n",
    "            x_intersection =  (q2 - q1)/(m1 - m2)\n",
    "\n",
    "            #print(m1, q1, m2, q2)\n",
    "            diss = dissimilarity_lines_difference(m1, q1, m2, q2, x_intersection >= max_x * 0.9 or x_intersection <= max_x * 0.1) * (len(original_or_times) / len(or_times))\n",
    "        else:\n",
    "            diss = 10000.0\n",
    "    else:\n",
    "        diss = 10000.0\n",
    "    #print(f\"Individ: {individual} : diss: {diss}\")\n",
    "    return diss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(individual, p_pop_item, p_add_new_effect):\n",
    "    if not individual: \n",
    "        effect = random.randint(0, n_effects - 1)\n",
    "        structure = effect_structure[effect]\n",
    "        new_gene = {\n",
    "            effect: \n",
    "            {param: round(random.uniform(range_[0], range_[1]), 2) for param, (_, range_) in structure.items()}\n",
    "        }\n",
    "        return new_gene \n",
    "    \n",
    "    offspring = deepcopy(individual)\n",
    "    items = list(offspring.items())\n",
    "    \n",
    "    available_effects = set(effects) - set(offspring.keys())\n",
    "    if not available_effects:\n",
    "        if random.random() > p_pop_item:\n",
    "            items.pop(random.randrange(len(items))) \n",
    "            return dict(items)\n",
    "        else:\n",
    "            return dict(items)\n",
    "        \n",
    "    effect = random.choice(list(available_effects))\n",
    "    structure = effect_structure[effect]\n",
    "    \n",
    "    #randomly decide between replacing an existing effect or adding a new one\n",
    "    if random.random() > p_add_new_effect:\n",
    "        new_gene = (\n",
    "            effect, \n",
    "            {param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "             for param, (_, range_) in structure.items()}\n",
    "        )\n",
    "        items.append(new_gene)\n",
    "    else:\n",
    "        index = random.randint(0, len(items) - 1)\n",
    "        new_gene = (\n",
    "            effect, \n",
    "            {param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "             for param, (_, range_) in structure.items()}\n",
    "        )\n",
    "        items[index] = new_gene\n",
    "    \n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def aggressive_mutation(individual, p_pop_item, p_add_new_effect, effects, effect_structure, p_mutation):\n",
    "    k = ceil(p_mutation * len(individual))  #number of mutation operations\n",
    "    print(k)\n",
    "    offspring = deepcopy(individual)\n",
    "    \n",
    "    for _ in range(k):  \n",
    "        if not offspring: \n",
    "            effect = random.randint(0, len(effects) - 1)\n",
    "            structure = effect_structure[effect]\n",
    "            new_gene = {\n",
    "                effect: \n",
    "                {param: round(random.uniform(range_[0], range_[1]), 2) for param, (_, range_) in structure.items()}\n",
    "            }\n",
    "            offspring = new_gene\n",
    "            continue\n",
    "\n",
    "        items = list(offspring.items())\n",
    "        \n",
    "        if random.random() > p_pop_item and len(items) > 0:\n",
    "            items.pop(random.randrange(len(items))) \n",
    "            offspring = dict(items)\n",
    "            continue\n",
    "        \n",
    "        available_effects = set(effects) - set(offspring.keys())\n",
    "        \n",
    "        if not available_effects:  # No available effects to add, just remove if p_pop_item > random\n",
    "            if random.random() > p_pop_item and len(items) > 0:\n",
    "                items.pop(random.randrange(len(items))) \n",
    "                offspring = dict(items)\n",
    "            continue\n",
    "        \n",
    "        effect = random.choice(list(available_effects))\n",
    "        structure = effect_structure[effect]\n",
    "        \n",
    "        # Decide between replacing an existing effect or adding a new one\n",
    "        if random.random() > p_add_new_effect:  # Add a new effect\n",
    "            new_gene = (\n",
    "                effect, \n",
    "                {param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "                 for param, (_, range_) in structure.items()}\n",
    "            )\n",
    "            items.append(new_gene)\n",
    "        else:  # Replace an existing effect\n",
    "            index = random.randint(0, len(items) - 1)\n",
    "            new_gene = (\n",
    "                effect, \n",
    "                {param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "                 for param, (_, range_) in structure.items()}\n",
    "            )\n",
    "            items[index] = new_gene\n",
    "        \n",
    "        offspring = dict(items)\n",
    "    \n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_mutation(individual):\n",
    "    if not individual: \n",
    "        return individual\n",
    "    offspring = deepcopy(individual)\n",
    "    key = random.choice(list(offspring.keys()))\n",
    "    structure = effect_structure[key]\n",
    "    offspring[key] = {\n",
    "        param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "        for param, (_, range_) in structure.items()\n",
    "    }\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{7: {'threshold_db': -31.18}, 1: {'delay_seconds': 1.08}, 0: {'rate_hz': 78.32}, 3: {'gain_db': -15.05}}\n"
     ]
    }
   ],
   "source": [
    "n_effects = 6\n",
    "effects = [i for i in range(n_effects)]\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (0.0, 100.0)), },# Chorus\n",
    "    1: { \"delay_seconds\": ('float', (0.0, 10.0)), },# Delay\n",
    "    2: { \"drive_db\": ('float', (0.0, 50.0)), },# Distortion\n",
    "    3: { \"gain_db\": ('float', (-50.0, 50.0)) },# Gain\n",
    "    4: { \"depth\": ('float', (0.0, 1.0)), },# Phaser\n",
    "    5: { \"wet_level\": ('float', (0.0, 1.0)), },# Reverb\n",
    "}\n",
    "effects_map = {\n",
    "    0: 'Chorus',\n",
    "    1: 'Delay',\n",
    "    2: 'Distortion',\n",
    "    3: 'Gain',\n",
    "    4: 'Phaser',\n",
    "    5: 'Reverb',\n",
    "}\n",
    "\n",
    "individ = {7: {'threshold_db': -31.18},\n",
    " 4: {'depth': 0.11},\n",
    " 5: {'wet_level': 0.04},\n",
    " 0: {'rate_hz': 78.32},\n",
    " 2: {'drive_db': 21.4}}\n",
    "\n",
    "print(aggressive_mutation(individ, 0.5, 0.5, effects, effect_structure, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inner_mutation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m individ \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m inner_mutation(individ)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inner_mutation' is not defined"
     ]
    }
   ],
   "source": [
    "individ = {}\n",
    "inner_mutation(individ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def crossover(parent_1, parent_2):\n",
    "    offspring_1 = deepcopy(parent_1)\n",
    "    offspring_2 = deepcopy(parent_2)\n",
    "    \n",
    "    set1, set2 = set(parent_1.keys()), set(parent_2.keys())\n",
    "    common_keys = list(set1 & set2) #find common and different keys\n",
    "    different_keys = list(set1 ^ set2)\n",
    "\n",
    "    #modify offspring based on common elements\n",
    "    if common_keys:\n",
    "        index_1 = len(common_keys) // 2\n",
    "        for i in range(index_1):\n",
    "            key = common_keys[i]\n",
    "            offspring_1[key], offspring_2[key] = offspring_2[key], offspring_1[key]\n",
    "\n",
    "    #modify offspring based on symmetric difference elements\n",
    "    if different_keys:\n",
    "        index_2 = len(different_keys) // 2\n",
    "        for j in range(index_2):\n",
    "            key = different_keys[j]\n",
    "            if key in offspring_1:\n",
    "                offspring_2[key] = offspring_1.pop(key)\n",
    "            else:\n",
    "                offspring_1[key] = offspring_2.pop(key)\n",
    "\n",
    "    return offspring_1, offspring_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "{4: {'depth': 0.8}, 2: {'drive_db': 24.83}, 5: {'wet_level': 0.53}, 3: {'gain_db': 13.94}, 0: {'rate_hz': 65.17}}\n",
      "{5: {'wet_level': 0.59}, 4: {'depth': 0.47}, 0: {'rate_hz': 78.04}}\n",
      "{4: {'depth': 0.8}, 5: {'wet_level': 0.53}, 3: {'gain_db': 13.94}, 0: {'rate_hz': 78.04}}\n",
      "{5: {'wet_level': 0.59}, 4: {'depth': 0.47}, 0: {'rate_hz': 65.17}, 2: {'drive_db': 24.83}}\n"
     ]
    }
   ],
   "source": [
    "indv1 = {4: {'depth': 0.8}, 2: {'drive_db': 24.83}, 5: {'wet_level': 0.53}, 3: {'gain_db': 13.94}, 0: {'rate_hz': 65.17}}\n",
    "indv2 = {5: {'wet_level': 0.59}, 4: {'depth': 0.47}, 0: {'rate_hz': 78.04}}\n",
    "\n",
    "o1, o2 = crossover(indv1, indv2)\n",
    "print(indv1)\n",
    "print(indv2)\n",
    "print(o1)\n",
    "print(o2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_focm(file_path, effected_file_path, constellation_map_alg, threshold, fit, pop, t_size):\n",
    "    tournament = random.choices(pop, k=t_size)\n",
    "    return min(tournament, key=lambda ind: fit(ind, file_path, effected_file_path, constellation_map_alg, threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection_lines_difference(plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out, fit, pop, t_size):\n",
    "    tournament = random.choices(pop, k=t_size)\n",
    "    return min(tournament, key=lambda ind: fit(ind, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_population(pop_size, effects, effect_structure):\n",
    "    pop = []\n",
    "    for _ in range(pop_size):\n",
    "        pop.append(create_individual(effects, effect_structure))\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA with FOCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_focm(file_path, effected_file_path, constellation_map_alg, threshold, fit, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size):\n",
    "  pop = init_population(pop_size, effects, effect_structure)\n",
    "  \n",
    "  best = {}\n",
    "\n",
    "  for i in range(0, n_iter):\n",
    "    print(f\"Iteration: {i}\")\n",
    "    selected = [tournament_selection_focm(file_path, effected_file_path, constellation_map_alg, threshold, fit, pop, t_size) for _ in range(0, pop_size)]\n",
    "    pairs = [[selected[i], selected[i + 1]] for i in range(len(selected))]\n",
    "    \n",
    "    offsprings = []\n",
    "    for x, y in pairs:\n",
    "        of1, of2 = crossover(x, y)\n",
    "        if random.choice([True, False]):\n",
    "          offsprings.append(of1)\n",
    "        else:\n",
    "          offsprings.append(of2)\n",
    "        \n",
    "    pop = [mutation(inner_mutation(x), p_pop_item, p_add_new_effect) for x in offsprings]\n",
    "\n",
    "    candidate_best = min(pop, key=lambda ind: fit(ind, file_path, effected_file_path, constellation_map_alg, threshold))\n",
    "    print(f\"Best candidate: {candidate_best}\")\n",
    "    print(f\"\\nCandidate fitness: {fit(candidate_best, file_path, effected_file_path, constellation_map_alg, threshold)} , best fitness: {fit(best, file_path, effected_file_path, constellation_map_alg, threshold)}\")\n",
    "    if fit(candidate_best, file_path, effected_file_path, constellation_map_alg, threshold) < fit(best, file_path, effected_file_path, constellation_map_alg, threshold):\n",
    "      best = candidate_best\n",
    "    print(f\"Best fitness at generation {i}: {fit(best, file_path, effected_file_path, constellation_map_alg, threshold)}\\n\")\n",
    "  return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_audio = \"G4_guitar.mp3\"\n",
    "effected_audio = \"G4_guitar_Delay_high.mp3\"\n",
    "constellation_map_alg = z_score_peaks_calculation\n",
    "fitness = fitness_focm\n",
    "threshold = 3\n",
    "pop_size = 30\n",
    "p_pop_item = 0.2\n",
    "p_add_new_effect = 0.5\n",
    "n_iter = 10\n",
    "t_size = 5\n",
    "\n",
    "GA_focm(original_audio, effected_audio, constellation_map_alg, threshold, fitness, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA with straight line comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_lines_comp(plain_audio_path, desired_audio_path, constellation_map_alg, threshold, fan_out, fit, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size):\n",
    "  pop = init_population(pop_size, effects, effect_structure)\n",
    "  \n",
    "  peaks_original = constellation_map_alg(desired_audio_path, threshold)\n",
    "  hashes0 = generate_hashes(peaks_original, fan_out)\n",
    "  hash_table = create_database(hashes0)\n",
    "\n",
    "  peaks_copy_original = constellation_map_alg(desired_audio_path, threshold)\n",
    "  hashes1 = generate_hashes(peaks_copy_original, fan_out)\n",
    "  copy_hash_table = deepcopy(hash_table)\n",
    "  time_pairs = search_database(copy_hash_table, hashes1)\n",
    "  or_times, sample_times = zip(*time_pairs)\n",
    "  popt1, _ = curve_fit(linear_func, or_times, sample_times)\n",
    "  m1, q1 = popt1\n",
    "  \n",
    "  best = {}\n",
    "\n",
    "  for i in range(0, n_iter):\n",
    "    time_start = time.time()\n",
    "    print(f\"Iteration: {i}\")\n",
    "    selected = [tournament_selection_lines_difference(plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out, fit, pop, t_size) for _ in range(0, pop_size)]\n",
    "    pairs = [[selected[i], selected[(i + 1) % len(selected)]] for i in range(len(selected))]    \n",
    "    \n",
    "    offsprings = []\n",
    "    for x, y in pairs:\n",
    "        of1, of2 = crossover(x, y)\n",
    "        if random.choice([True, False]):\n",
    "          offsprings.append(of1)\n",
    "        else:\n",
    "          offsprings.append(of2)\n",
    "\n",
    "    pop = [mutation(inner_mutation(x), p_pop_item, p_add_new_effect) for x in offsprings]\n",
    "    print(len(pop))\n",
    "\n",
    "    candidate_best = min(pop, key=lambda ind: fit(ind, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out))\n",
    "    print(f\"Best candidate: {candidate_best}\")\n",
    "    print(f\"\\nCandidate fitness: {fit(candidate_best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out)} , best fitness: {fit(best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out)}\")\n",
    "    if fit(candidate_best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out) < fit(best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out):\n",
    "      best = candidate_best\n",
    "    print(f\"Best fitness at generation {i}: {fit(best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out)}\\n\")\n",
    "    print(f'Time for iteration {i}: {time.time() - time_start}')\n",
    "    if fit(best, plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out) < 0.5:\n",
    "      break\n",
    "  return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_audio = \"../audios/G4_guitar.mp3\"\n",
    "desired_audio = \"../audios/G4_guitar_Delay_low.mp3\"\n",
    "constellation_map_alg = z_score_peaks_calculation\n",
    "fitness = fitness_lines_difference\n",
    "threshold = 1.5\n",
    "fan_out = 20\n",
    "pop_size = 100\n",
    "p_pop_item = 0.8,\n",
    "p_add_new_effect = 0.5\n",
    "n_iter = 20\n",
    "t_size = 5\n",
    "\n",
    "GA_lines_comp(plain_audio, desired_audio, constellation_map_alg, threshold, fan_out, fitness, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA applied to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_midi(audio_path, midi_path, note_segmentation, model_confidence, instrument_program):\n",
    "    _, midi_data, __ = inference.predict(\n",
    "        audio_path,    \n",
    "        model_or_model_path = ICASSP_2022_MODEL_PATH, \n",
    "        onset_threshold = note_segmentation, # 0.6 note segmentation 1) how easily a note should be split into two. (split notes <- ..0.5.. -> merge notes)\n",
    "        frame_threshold = model_confidence, # 0.6 model confidence threshold 2) the model confidence required to create a note. (more notes <- ..0.3.. -> fewer notes)\n",
    "    )\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        instrument.program = instrument_program #distortion guitar program 30\n",
    "\n",
    "    midi_data.write(midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_mp3(midi_file, audio_path, soundfont):\n",
    "    #convert MIDI to WAV using FluidSynth\n",
    "    fs = FluidSynth(soundfont)\n",
    "    wav_file = midi_file.replace('.midi', '.wav').replace('.mid', '.wav')\n",
    "    fs.midi_to_audio(midi_file, wav_file)\n",
    "\n",
    "    #convert WAV to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(wav_file)\n",
    "    sound.export(audio_path, format=\"mp3\")\n",
    "\n",
    "    print(f\"Conversion complete: {audio_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_GA_execution(df, \n",
    "                         note_segmentation,\n",
    "                         model_confidence,\n",
    "                         instrument_program,\n",
    "                         constellation_map_alg,\n",
    "                         fitness,\n",
    "                         threshold,\n",
    "                         fan_out,\n",
    "                         pop_size,\n",
    "                         p_pop_item,\n",
    "                         p_add_new_effect,\n",
    "                         n_iter,\n",
    "                         t_size,\n",
    "                         soundfont,\n",
    "                         clear_audio_path,\n",
    "                         midi_path):\n",
    "    temp_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        desired_audio_path = '../dataset_creation/audios/' + row[\"audio_name\"]\n",
    "        mp3_to_midi(desired_audio_path, midi_path, note_segmentation, model_confidence, instrument_program)\n",
    "        midi_to_mp3(midi_path, clear_audio_path, soundfont)\n",
    "        \n",
    "        best_invdivid = GA_lines_comp(clear_audio_path, desired_audio_path, constellation_map_alg, threshold, fan_out, fitness, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size)    \n",
    "        temp_data.append(best_invdivid)\n",
    "        df['GA_effects'] = pd.Series(temp_data)\n",
    "        df.to_csv('../dataset_creation/dataset_audios.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting MIDI for ../dataset_creation/audios/0.mp3...\n",
      "Conversion complete: clear_audio.mp3\n",
      "Iteration: 0\n",
      "100\n",
      "Best candidate: {1: {'delay_seconds': 3.89}, 5: {'wet_level': 0.98}, 2: {'drive_db': 43.72}, 4: {'depth': 0.43}}\n",
      "\n",
      "Candidate fitness: 276.7267454365586 , best fitness: 10000.0\n",
      "Best fitness at generation 0: 276.7267454365586\n",
      "\n",
      "Time for iteration 0: 469.39876651763916\n",
      "Iteration: 1\n",
      "100\n",
      "Best candidate: {3: {'gain_db': 35.84}, 1: {'delay_seconds': 3.41}, 2: {'drive_db': 15.78}}\n",
      "\n",
      "Candidate fitness: 302.7279769649559 , best fitness: 276.7267454365586\n",
      "Best fitness at generation 1: 276.7267454365586\n",
      "\n",
      "Time for iteration 1: 460.27390336990356\n",
      "Iteration: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m clear_audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclear_audio.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m midi_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclear_midi.mid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mdataset_GA_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnote_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minstrument_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mp_pop_item\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mp_add_new_effect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mt_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msoundfont\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mclear_audio_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmidi_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[113], line 24\u001b[0m, in \u001b[0;36mdataset_GA_execution\u001b[1;34m(df, note_segmentation, model_confidence, instrument_program, constellation_map_alg, fitness, threshold, fan_out, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size, soundfont, clear_audio_path, midi_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m mp3_to_midi(desired_audio_path, midi_path, note_segmentation, model_confidence, instrument_program)\n\u001b[0;32m     22\u001b[0m midi_to_mp3(midi_path, clear_audio_path, soundfont)\n\u001b[1;32m---> 24\u001b[0m best_invdivid \u001b[38;5;241m=\u001b[39m \u001b[43mGA_lines_comp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclear_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_pop_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_add_new_effect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_size\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     25\u001b[0m temp_data\u001b[38;5;241m.\u001b[39mappend(best_invdivid)\n\u001b[0;32m     26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGA_effects\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(temp_data)\n",
      "Cell \u001b[1;32mIn[117], line 21\u001b[0m, in \u001b[0;36mGA_lines_comp\u001b[1;34m(plain_audio_path, desired_audio_path, constellation_map_alg, threshold, fan_out, fit, pop_size, p_pop_item, p_add_new_effect, n_iter, t_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m selected \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtournament_selection_lines_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplain_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mor_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [[selected[i], selected[(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected)]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(selected))]    \n\u001b[0;32m     24\u001b[0m offsprings \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[117], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m selected \u001b[38;5;241m=\u001b[39m [\u001b[43mtournament_selection_lines_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplain_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mor_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, pop_size)]\n\u001b[0;32m     22\u001b[0m pairs \u001b[38;5;241m=\u001b[39m [[selected[i], selected[(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected)]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(selected))]    \n\u001b[0;32m     24\u001b[0m offsprings \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m, in \u001b[0;36mtournament_selection_lines_difference\u001b[1;34m(plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out, fit, pop, t_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtournament_selection_lines_difference\u001b[39m(plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out, fit, pop, t_size):\n\u001b[0;32m      2\u001b[0m     tournament \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(pop, k\u001b[38;5;241m=\u001b[39mt_size)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtournament\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mor_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m, in \u001b[0;36mtournament_selection_lines_difference.<locals>.<lambda>\u001b[1;34m(ind)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtournament_selection_lines_difference\u001b[39m(plain_audio_path, hash_table, m1, q1, or_times, constellation_map_alg, threshold, fan_out, fit, pop, t_size):\n\u001b[0;32m      2\u001b[0m     tournament \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(pop, k\u001b[38;5;241m=\u001b[39mt_size)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(tournament, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m ind: \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mor_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstellation_map_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfan_out\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[98], line 7\u001b[0m, in \u001b[0;36mfitness_lines_difference\u001b[1;34m(individual, plain_audio_path, hash_table, m1, q1, original_or_times, constellation_map_alg, threshold, fan_out)\u001b[0m\n\u001b[0;32m      4\u001b[0m     effect_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[effects_map[effect_key]]\n\u001b[0;32m      5\u001b[0m     board\u001b[38;5;241m.\u001b[39mappend(effect_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams))\n\u001b[1;32m----> 7\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_effected_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplain_audio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m new_peaks \u001b[38;5;241m=\u001b[39m constellation_map_alg(output_file_path, threshold)\n\u001b[0;32m     10\u001b[0m new_hashes \u001b[38;5;241m=\u001b[39m generate_hashes(new_peaks, fan_out)\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mcreate_effected_audio\u001b[1;34m(board, file_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(f\u001b[38;5;241m.\u001b[39msamplerate)\n\u001b[0;32m      7\u001b[0m             effected \u001b[38;5;241m=\u001b[39m board(chunk, f\u001b[38;5;241m.\u001b[39msamplerate, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m             \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43meffected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_file\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset_creation/dataset_audios.csv')\n",
    "\n",
    "note_segmentation = 0.6\n",
    "model_confidence = 0.6\n",
    "instrument_program = 30\n",
    "constellation_map_alg = z_score_peaks_calculation\n",
    "fitness = fitness_lines_difference\n",
    "threshold = 1.5\n",
    "fan_out = 20\n",
    "pop_size = 100\n",
    "p_pop_item = 0.8\n",
    "p_add_new_effect = 0.2\n",
    "n_iter = 10\n",
    "t_size = 5\n",
    "soundfont = '../audio2midi2audio/FluidR3_GM.sf2'  # Path to your SoundFont file\n",
    "clear_audio_path = 'clear_audio.mp3'\n",
    "midi_path = 'clear_midi.mid'\n",
    "\n",
    "dataset_GA_execution(df, \n",
    "                    note_segmentation,\n",
    "                    model_confidence,\n",
    "                    instrument_program,\n",
    "                    constellation_map_alg,\n",
    "                    fitness,\n",
    "                    threshold,\n",
    "                    fan_out,\n",
    "                    pop_size,\n",
    "                    p_pop_item,\n",
    "                    p_add_new_effect,\n",
    "                    n_iter,\n",
    "                    t_size,\n",
    "                    soundfont,\n",
    "                    clear_audio_path,\n",
    "                    midi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset_creation/dataset_audios.csv')\n",
    "\n",
    "data = [{6: {'threshold_db': 0.09}},]\n",
    "\n",
    "# Assign the list to the new column\n",
    "df['GA_effects'] = pd.Series(data)\n",
    "\n",
    "df.to_csv('../dataset_creation/dataset_audios.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual = {}\n",
    "\n",
    "for effect_key, params in individual.items():\n",
    "    print(effect_key, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset_model_test.csv')\n",
    "\n",
    "print(df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA_testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
