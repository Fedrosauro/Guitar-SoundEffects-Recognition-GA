{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df before dropping [] values: \n",
      "(960, 10)\n",
      "Df after dropping [] values: \n",
      "(951, 10)\n",
      "Analysis on full dataset:\n",
      "Full Data - Basic Statistics:\n",
      "       dissimilarity   threshold     fan_out  max_distance_atan  \\\n",
      "count     951.000000  951.000000  951.000000         951.000000   \n",
      "mean      308.313720    2.501052   14.994742          95.005258   \n",
      "std       384.894960    0.408462    5.002628           5.002628   \n",
      "min         0.252577    2.000000   10.000000          90.000000   \n",
      "25%        52.900602    2.000000   10.000000          90.000000   \n",
      "50%       102.923642    2.500000   10.000000         100.000000   \n",
      "75%       381.686112    3.000000   20.000000         100.000000   \n",
      "max      1000.000000    3.000000   20.000000         100.000000   \n",
      "\n",
      "       onset_threshold  frame_threshold  max_key_distance  \n",
      "count       951.000000       951.000000        951.000000  \n",
      "mean          0.499685         0.499054         29.989485  \n",
      "std           0.100052         0.100048         10.005256  \n",
      "min           0.400000         0.400000         20.000000  \n",
      "25%           0.400000         0.400000         20.000000  \n",
      "50%           0.400000         0.400000         20.000000  \n",
      "75%           0.600000         0.600000         40.000000  \n",
      "max           0.600000         0.600000         40.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 951 entries, 0 to 959\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   dissimilarity      951 non-null    float64\n",
      " 1   threshold          951 non-null    float64\n",
      " 2   fan_out            951 non-null    int64  \n",
      " 3   max_distance_atan  951 non-null    int64  \n",
      " 4   onset_threshold    951 non-null    float64\n",
      " 5   frame_threshold    951 non-null    float64\n",
      " 6   max_key_distance   951 non-null    int64  \n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 59.4 KB\n",
      "None\n",
      "Full Data - Best parameters:\n",
      "dissimilarity          0.252577\n",
      "threshold              3.000000\n",
      "fan_out               20.000000\n",
      "max_distance_atan    100.000000\n",
      "onset_threshold        0.600000\n",
      "frame_threshold        0.400000\n",
      "max_key_distance      40.000000\n",
      "Name: 938, dtype: float64\n",
      "\n",
      "Analysis on grouped dataset (mean dissimilarity):\n",
      "Grouped Data - Basic Statistics:\n",
      "       threshold    fan_out  max_distance_atan  onset_threshold  \\\n",
      "count  96.000000  96.000000          96.000000        96.000000   \n",
      "mean    2.500000  15.000000          95.000000         0.500000   \n",
      "std     0.410391   5.026247           5.026247         0.100525   \n",
      "min     2.000000  10.000000          90.000000         0.400000   \n",
      "25%     2.000000  10.000000          90.000000         0.400000   \n",
      "50%     2.500000  15.000000          95.000000         0.500000   \n",
      "75%     3.000000  20.000000         100.000000         0.600000   \n",
      "max     3.000000  20.000000         100.000000         0.600000   \n",
      "\n",
      "       frame_threshold  max_key_distance  dissimilarity  \n",
      "count        96.000000         96.000000      96.000000  \n",
      "mean          0.500000         30.000000     308.526519  \n",
      "std           0.100525         10.052494     258.470648  \n",
      "min           0.400000         20.000000      48.751187  \n",
      "25%           0.400000         20.000000      89.577229  \n",
      "50%           0.500000         30.000000     192.202217  \n",
      "75%           0.600000         40.000000     561.261652  \n",
      "max           0.600000         40.000000     919.420187  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   threshold          96 non-null     float64\n",
      " 1   fan_out            96 non-null     int64  \n",
      " 2   max_distance_atan  96 non-null     int64  \n",
      " 3   onset_threshold    96 non-null     float64\n",
      " 4   frame_threshold    96 non-null     float64\n",
      " 5   max_key_distance   96 non-null     int64  \n",
      " 6   dissimilarity      96 non-null     float64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 5.4 KB\n",
      "None\n",
      "Grouped Data - Best parameters:\n",
      "threshold              3.000000\n",
      "fan_out               10.000000\n",
      "max_distance_atan    100.000000\n",
      "onset_threshold        0.400000\n",
      "frame_threshold        0.600000\n",
      "max_key_distance      40.000000\n",
      "dissimilarity         48.751187\n",
      "Name: 75, dtype: float64\n",
      "Analysis complete. Check the generated PNG files for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#load the CSV file\n",
    "df = pd.read_csv('./results/df_model_tests.csv')\n",
    "\n",
    "print(f\"Df before dropping [] values: \\n{df.shape}\")\n",
    "\n",
    "#drop rows for which \"generated_midi_data\" is []\n",
    "df = df[df['generated_midi_data'].apply(lambda x: x != '[]')]\n",
    "\n",
    "print(f\"Df after dropping [] values: \\n{df.shape}\")\n",
    "\n",
    "#remove irrelevant columns\n",
    "df = df.drop(['original_midi_data', 'generated_midi_data', 'individual'], axis=1)\n",
    "\n",
    "#list of parameter columns\n",
    "param_columns = ['threshold', 'fan_out', 'max_distance_atan', 'onset_threshold', 'frame_threshold', 'max_key_distance']\n",
    "\n",
    "#function to perform analysis\n",
    "def analyze_data(data, title_prefix):\n",
    "    #1) Basic statistics and information\n",
    "    print(f\"{title_prefix} - Basic Statistics:\")\n",
    "    print(data.describe())\n",
    "    print(data.info())\n",
    "\n",
    "    #2) Find the row(s) with the lowest dissimilarity\n",
    "    best_params = data.loc[data['dissimilarity'].idxmin()]\n",
    "    print(f\"{title_prefix} - Best parameters:\")\n",
    "    print(best_params)\n",
    "\n",
    "    #3) Correlation analysis\n",
    "    correlation_matrix = data.corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title(f'{title_prefix} - Correlation Heatmap')\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_correlation_heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "    #4) Pairplot\n",
    "    sns.pairplot(data, vars=['dissimilarity'] + param_columns)\n",
    "    plt.suptitle(f'{title_prefix} - Pairplot', y=1.02)\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_pairplot.png')\n",
    "    plt.close()\n",
    "\n",
    "    #5) Feature importance using PCA\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[param_columns])\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_data)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': param_columns,\n",
    "        'importance': pca.explained_variance_ratio_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "    plt.title(f'{title_prefix} - Feature Importance')\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "    #6) Scatter plots for top 3 important features vs dissimilarity\n",
    "    top_features = feature_importance['feature'][:3].tolist()\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    for i, feature in enumerate(top_features):\n",
    "        sns.scatterplot(x=feature, y='dissimilarity', data=data, ax=axes[i])\n",
    "        axes[i].set_title(f'{feature} vs Dissimilarity')\n",
    "    plt.suptitle(f'{title_prefix} - Top Features Scatter Plots', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_top_features_scatter.png')\n",
    "    plt.close()\n",
    "\n",
    "    #7) 3D scatter plot for top 3 features\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(data[top_features[0]], data[top_features[1]], data[top_features[2]], \n",
    "                         c=data['dissimilarity'], cmap='viridis')\n",
    "    ax.set_xlabel(top_features[0])\n",
    "    ax.set_ylabel(top_features[1])\n",
    "    ax.set_zlabel(top_features[2])\n",
    "    plt.colorbar(scatter, label='Dissimilarity')\n",
    "    plt.title(f'{title_prefix} - 3D Scatter Plot of Top 3 Features')\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_3d_scatter.png')\n",
    "    plt.close()\n",
    "\n",
    "    #8) Histogram of dissimilarity values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data['dissimilarity'], kde=True)\n",
    "    plt.title(f'{title_prefix} - Distribution of Dissimilarity Values')\n",
    "    plt.xlabel('Dissimilarity')\n",
    "    plt.savefig(f'./results_images/{title_prefix.lower().replace(\" \", \"_\")}_dissimilarity_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "#analyze full dataset\n",
    "print(\"Analysis on full dataset:\")\n",
    "analyze_data(df, \"Full Data\")\n",
    "\n",
    "#group by parameter combinations and calculate mean and std of dissimilarity\n",
    "grouped_df = df.groupby(param_columns).agg({\n",
    "    'dissimilarity': ['mean', 'std']\n",
    "}).reset_index()\n",
    "grouped_df.columns = param_columns + ['dissimilarity_mean', 'dissimilarity_std']\n",
    "\n",
    "#analyze grouped dataset\n",
    "print(\"\\nAnalysis on grouped dataset (mean dissimilarity):\")\n",
    "analyze_data(grouped_df.drop('dissimilarity_std', axis=1).rename(columns={'dissimilarity_mean': 'dissimilarity'}), \"Grouped Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
