{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model for MIDI file generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pretty_midi\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH, inference\n",
    "from pedalboard import Pedalboard, Reverb, Chorus, Distortion, Delay, Phaser, Compressor, Gain, Clipping\n",
    "from pedalboard.io import AudioFile\n",
    "from midi2audio import FluidSynth \n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(effects, effect_structure):\n",
    "    n_effects_chosen = random.randint(1, len(effects))\n",
    "    selected_effects = random.sample(effects, n_effects_chosen)\n",
    "    \n",
    "    individ = {}\n",
    "    for effect in selected_effects:\n",
    "        if effect in effect_structure:\n",
    "            structure = effect_structure[effect]\n",
    "            individ[effect] = {\n",
    "                param: round(random.uniform(range_[0], range_[1]), 2) \n",
    "                for param, (_, range_) in structure.items()\n",
    "            }\n",
    "    return individ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_instrument_midi(filename, program, min_duration, max_duration, min_note, max_note):\n",
    "    # Create a PrettyMIDI object\n",
    "    midi_data = pretty_midi.PrettyMIDI()\n",
    "    \n",
    "    # Create an Instrument instance for a distortion instrument\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "    \n",
    "    # Determine the length of the MIDI in seconds\n",
    "    duration = random.randint(min_duration, max_duration)\n",
    "    min_note_number = pretty_midi.note_name_to_number(min_note)\n",
    "    max_note_number = pretty_midi.note_name_to_number(max_note)\n",
    "    \n",
    "    # Generate random notes\n",
    "    current_time = 0.0\n",
    "    while current_time < duration:\n",
    "        note_number = random.randint(min_note_number, max_note_number)\n",
    "        \n",
    "        note_duration = random.uniform(0.1, 1.0)\n",
    "        \n",
    "        # Ensure that the note ends before the total duration\n",
    "        note_end_time = min(current_time + note_duration, duration)\n",
    "        \n",
    "        # Create a Note instance and add it to the instrument instrument\n",
    "        note = pretty_midi.Note(\n",
    "            velocity=random.randint(60, 127),  # Random velocity\n",
    "            pitch=note_number,\n",
    "            start=current_time,\n",
    "            end=note_end_time\n",
    "        )\n",
    "        instrument.notes.append(note)\n",
    "        \n",
    "        # Update the current time\n",
    "        current_time = note_end_time\n",
    "    \n",
    "    # Add the instrument instrument to the PrettyMIDI object\n",
    "    midi_data.instruments.append(instrument)\n",
    "    \n",
    "    # Write out the MIDI data to a file\n",
    "    midi_data.write(filename)\n",
    "    \n",
    "    return midi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effected_audio(board, file_path, output_file):\n",
    "    with AudioFile(file_path) as f:\n",
    "        with AudioFile(output_file, 'w', f.samplerate, f.num_channels) as o:\n",
    "            while f.tell() < f.frames:\n",
    "                chunk = f.read(f.samplerate)\n",
    "                effected = board(chunk, f.samplerate, reset=False)\n",
    "                o.write(effected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_mp3(midi_file, mp3_file, soundfont):\n",
    "    #convert MIDI to WAV using FluidSynth\n",
    "    fs = FluidSynth(soundfont)\n",
    "    wav_file = midi_file.replace('.midi', '.wav').replace('.mid', '.wav')\n",
    "    fs.midi_to_audio(midi_file, wav_file)\n",
    "\n",
    "    #convert WAV to MP3 using pydub\n",
    "    sound = AudioSegment.from_wav(wav_file)\n",
    "    sound.export(mp3_file, format=\"mp3\")\n",
    "    \n",
    "def mp3_to_midi(audio_path):\n",
    "    _, midi_data, __ = inference.predict(\n",
    "        audio_path,    \n",
    "        model_or_model_path = ICASSP_2022_MODEL_PATH, \n",
    "        onset_threshold = 0.6, #note segmentation 1) how easily a note should be split into two. (split notes <- ..0.5.. -> merge notes)\n",
    "        frame_threshold = 0.6, #model confidence threshold 2) the model confidence required to create a note. (more notes <- ..0.3.. -> fewer notes)\n",
    "    )\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        instrument.program = 30 #distortion guitar program\n",
    "            \n",
    "    return midi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_db_creation(data, n_data, midi_file, mp3_file, csv_filename, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map):\n",
    "    for _ in range(n_data):\n",
    "        midi_data_original = generate_random_instrument_midi(midi_file, program, min_duration, max_duration, min_note, max_note)\n",
    "        midi_to_mp3(midi_file, mp3_file, soundfont)\n",
    "        individual = create_individual(effects, effect_structure)\n",
    "        board = Pedalboard([])\n",
    "        for effect_key, params in individual.items():\n",
    "            effect_class = globals()[effects_map[effect_key]]\n",
    "            board.append(effect_class(**params))\n",
    "            \n",
    "        effected_audio_name = \"audios/effected_audio.mp3\"\n",
    "        create_effected_audio(board, mp3_file, effected_audio_name)\n",
    "        new_midi_generated = mp3_to_midi(effected_audio_name)\n",
    "        data[\"original_midi_data\"].append(midi_data_original.instruments[0].notes)\n",
    "        if new_midi_generated.instruments:\n",
    "            data[\"generated_midi_data\"].append(new_midi_generated.instruments[0].notes)\n",
    "        else:\n",
    "            data[\"generated_midi_data\"].append(new_midi_generated.instruments)\n",
    "    \n",
    "    # Once all the data is collected, you can create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"CSV file '{csv_filename}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_generation(index, midi_file, mp3_file, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map):\n",
    "    # Create temporary MIDI and MP3 files for each parallel process\n",
    "    with tempfile.NamedTemporaryFile(suffix='.mid', delete=False) as temp_midi, tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_mp3:\n",
    "        temp_midi_name = temp_midi.name\n",
    "        temp_mp3_name = temp_mp3.name\n",
    "        \n",
    "        # Copy the original midi and mp3 file to the temporary file locations\n",
    "        shutil.copy(midi_file, temp_midi_name)\n",
    "        shutil.copy(mp3_file, temp_mp3_name)\n",
    "        \n",
    "        # Dictionary to hold the data for this individual run\n",
    "        result_data = {\n",
    "            \"original_midi_data\": [],\n",
    "            \"generated_midi_data\": [],\n",
    "        }\n",
    "\n",
    "        # Generate the MIDI data and apply effects\n",
    "        midi_data_original = generate_random_instrument_midi(temp_midi_name, program, min_duration, max_duration, min_note, max_note)\n",
    "        midi_to_mp3(temp_midi_name, temp_mp3_name, soundfont)\n",
    "        individual = create_individual(effects, effect_structure)\n",
    "        board = Pedalboard([])\n",
    "        for effect_key, params in individual.items():\n",
    "            effect_class = globals()[effects_map[effect_key]]\n",
    "            board.append(effect_class(**params))\n",
    "        \n",
    "        # Apply effects and create the effected audio\n",
    "        effected_audio_name = tempfile.mktemp(suffix='.mp3')  # Temporary file for effected audio\n",
    "        create_effected_audio(board, temp_mp3_name, effected_audio_name)\n",
    "        new_midi_generated = mp3_to_midi(effected_audio_name)\n",
    "\n",
    "        result_data[\"original_midi_data\"].append(midi_data_original.instruments[0].notes)\n",
    "        if new_midi_generated.instruments:\n",
    "            result_data[\"generated_midi_data\"].append(new_midi_generated.instruments[0].notes)\n",
    "        else:\n",
    "            result_data[\"generated_midi_data\"].append(new_midi_generated.instruments)\n",
    "\n",
    "        # Clean up temporary files\n",
    "        Path(temp_midi_name).unlink(missing_ok=True)\n",
    "        Path(temp_mp3_name).unlink(missing_ok=True)\n",
    "        Path(effected_audio_name).unlink(missing_ok=True)\n",
    "\n",
    "        return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_db_creation_parallel(data, n_data, midi_file, mp3_file, csv_filename, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map):\n",
    "    n_workers = os.cpu_count() - 1\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_data_generation, i, midi_file, mp3_file, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map)\n",
    "            for i in range(n_data)\n",
    "        ]\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result_data = future.result()\n",
    "            data[\"original_midi_data\"].extend(result_data[\"original_midi_data\"])\n",
    "            data[\"generated_midi_data\"].extend(result_data[\"generated_midi_data\"])\n",
    "\n",
    "    # Once all the data is collected, create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"CSV file '{csv_filename}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"original_midi_data\": [],\n",
    "    \"generated_midi_data\": [], \n",
    "}\n",
    "\n",
    "n_data = 10000\n",
    "midi_file = 'output.mid'\n",
    "mp3_file = 'output.mp3'\n",
    "csv_filename = \"dataset_midis.csv\"\n",
    "soundfont = '../audio2midi2audio/FluidR3_GM.sf2'  # Path to your SoundFont file\n",
    "program = 30\n",
    "min_note = 'E2'\n",
    "max_note = 'E6' # Generate a random note between MIDI note 40 (E2) and 88 (E6)\n",
    "min_duration = 3\n",
    "max_duration = 20\n",
    "n_effects = 6\n",
    "effects = [i for i in range(n_effects)]\n",
    "effect_structure = {\n",
    "    0: { \"rate_hz\": ('float', (0.0, 100.0)), },# Chorus\n",
    "    1: { \"delay_seconds\": ('float', (0.0, 10.0)), },# Delay\n",
    "    2: { \"drive_db\": ('float', (0.0, 50.0)), },# Distortion\n",
    "    3: { \"gain_db\": ('float', (-50.0, 50.0)) },# Gain\n",
    "    4: { \"depth\": ('float', (0.0, 1.0)), },# Phaser\n",
    "    5: { \"wet_level\": ('float', (0.0, 1.0)), },# Reverb\n",
    "}\n",
    "effects_map = {\n",
    "    0: 'Chorus',\n",
    "    1: 'Delay',\n",
    "    2: 'Distortion',\n",
    "    3: 'Gain',\n",
    "    4: 'Phaser',\n",
    "    5: 'Reverb',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_model_db_creation_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmidi_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmp3_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoundfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_note\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_note\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffect_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffects_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m, in \u001b[0;36mtest_model_db_creation_parallel\u001b[1;34m(data, n_data, midi_file, mp3_file, csv_filename, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Collect results as they complete\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[1;32m---> 12\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_midi_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(result_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_midi_data\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_midi_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(result_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_midi_data\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\pelli\\anaconda3\\envs\\tensorflow_v2\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\pelli\\anaconda3\\envs\\tensorflow_v2\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "test_model_db_creation_parallel(data, n_data, midi_file, mp3_file, csv_filename, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "CSV file 'dataset_midis.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "test_model_db_creation(data, n_data, midi_file, mp3_file, csv_filename, soundfont, program, min_note, max_note, min_duration, max_duration, effects, effect_structure, effects_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting MIDI for audios/effected_audio.mp3...\n",
      "{'resolution': 220, '_tick_scales': [(0, 0.0022727272727272726)], '_PrettyMIDI__tick_to_time': [0], 'instruments': [], 'key_signature_changes': [], 'time_signature_changes': [], 'lyrics': [], 'text_events': []}\n",
      "Tempo changes: (array([0.]), array([120.]))\n",
      "Time signature changes: []\n",
      "Instruments: []\n",
      "<pretty_midi.pretty_midi.PrettyMIDI object at 0x000002B58F608490>\n"
     ]
    }
   ],
   "source": [
    "midi_data = mp3_to_midi('audios/effected_audio.mp3')\n",
    "# Using __dict__ to see instance attributes\n",
    "print(midi_data.__dict__)\n",
    "\n",
    "# Accessing some specific properties\n",
    "print(\"Tempo changes:\", midi_data.get_tempo_changes())\n",
    "print(\"Time signature changes:\", midi_data.time_signature_changes)\n",
    "print(\"Instruments:\", midi_data.instruments)\n",
    "print(midi_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
